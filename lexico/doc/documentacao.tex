\documentclass[11pt]{article}
\usepackage{sbc-template}
\usepackage[portuguese]{babel}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{indentfirst}

\lstset{ %
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it is 1 each line will be numbered
numbersep=7pt,                   % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,           % adds a frame around the code
tabsize=2,          % sets default tabsize to 2 spaces
breaklines=true,        % sets automatic line breaking
breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)},          % if you want to add a comment within your code
extendedchars=true,
literate={á}{{\'a}}1 {ã}{{\~a}}1 {é}{{\'e}}1
}

\title{Documentação do analisador léxico}

\author{Lucas Amaral $^1$}

\address{Departamento de Ciência da Computação - Universidade de Brasília}

\begin{document}
\maketitle


\section{Descrição do trabalho}

Este trabalho consiste na implementação do analisador léxico utilizando a ferramenta Flex.
Uma pequena modificação da gramática foi feita em relação à anteriormente apresentada. 
Mais especificamente, as diretrizes de entrada e saída foram adicionadas, 
como vai ser exibido posteriormente.

\section{Analisador Léxico}

\subsection{Visão geral do projeto}

O programa irá receber, por linha de comando, o arquivo a ser escaneado. Cada token será
lido e terá seu nome correspondente impresso na tela. 
Quebras de linha no arquivo fonte são replicadas na saída. 
Caso algum erro ocorra, este será guardado e só será notificado no final da 
execução do programa. É utilizada uma estrutura em uma lista para armazenamento dos erros.

\subsection{Tratamento de erros}

A função \emph{handle\_token(int token)} é utilizada para fazer o tratamento de um token lido,
imprimindo na tela os adequados e adicionando à lista de erros caso algo de incorreto seja
encontrado. Ela consiste, basicamente, de um vetor contendo os tokens como strings, e \emph{if-then-else} com um tratamento
apropriado para cada token. Quando um token não identificado é lido, o código seguinte é 
executado. Nele \emph{comp\_error\_t} é uma estrutura que representa um erro, contendo um tipo de
erro e uma mensagem a ser mostrada. A lista de erros é chamada de \emph{list\_error\_t}. A linha
e coluna onde o token inválido é encontrado são adicionadas no início da mensagem. Nele,
\emph{make\_error} recebe como parâmetro o tipo de erro (léxico, sintático, etc), o token que causou o erro
e a linha e coluna onde o erro foi identificado.


\begin{lstlisting}[basicstyle=\small]
    comp_error_t* err = make_error(0, yytext, line, col);
    add_error(&error_list_root, err);
\end{lstlisting}

As funções \emph{make\_error} e \emph{add\_error} são implementadas em um arquivo separado, chamado
\emph{list\_error}. A primeira aloca uma struct do tipo comp\_error\_t e inicializa com os parâmetros, retornando o ponteiro,
e a segunda adiciona um erro em uma lista dada no primeiro argumento.

Este tratamento foi escolhido por dois motivos:

\begin{itemize}[leftmargin=.5in]
  \item Organização da saída do programa
  \item Reaproveitamento da estrutura de tratamento de erros para os próximos trabalhos
\end{itemize}

Vale ressaltar que o único tipo de erro tratado nesta fase é o erro estritamente léxico. 
Apenas tokens inválidos são identificados como um erro por este analisador.
Exemplos de erros léxicos são números seguidos de letras, como ``954asd", identificadores iniciados com underscore, como ``\_func",
e caracteres não aceitos na linguagem, como ``ç".

Foi incluida também uma função \emph{main} para realização da do recebimento do nome do
arquivo por linha de comando, chamada à função específica do parser e impressão dos resultados.


\section{Sobre a gramática da linguagem}

No final deste relatório encontra-se a gramática para a linguagem. Em relação à entrega anterior, houveram apenas duas mudanças.
A primeira foi a adição das diretivas de entrada e saída. Mais especificamente, as seguintes regras foram adicionadas.


\begin{lstlisting}[basicstyle=\small]
stmt:
    | io_stmt ';'

io_stmt:
    | 'readInt'
    | 'readFloat'
    | 'readBool'
    | 'print' expr
\end{lstlisting}

A segunda foi a modificação das regras para constantes booleanas na gramática,
juntando ambas em um único token. Seu valor vai ser retornado internamente no token.
No código abaixo, onde existe ``BOOLVAL" existiam duas regras, ``TRUE" e ``FALSE".

\begin{lstlisting}[basicstyle=\small]
basic_value: 
    INT
    | FLOAT
    | BOOLVAL
    | ID
    | '(' ')'
\end{lstlisting}

O resto da gramática continua exatamente como dito no primeiro relatório.

\section{Descrição dos arquivos de teste}

Existem 4 arquivos de teste contidos na pasta \emph{testes}.
\begin{itemize}
    \item O arquivo \emph{correto1.txt} mostra um programa simples da linguagem. Observar os operadores e os identificadores com números.
    \item O arquivo \emph{correto2.txt} contém mais alguns exemplos, como constantes booleanas, comentários e erros sendo ignorados dentro dos comentários, 
        em especial, identificador começando com underscore.
    \item O arquivo \emph{incorreto1.txt} já contém alguns erros. Identificadores começando com underscore e caracteres inválidos estão presentes.
    \item O arquivo \emph{incorreto2.txt} também contém alguns erros. Em especial vale notar que \emph{\#} não inicia um comentário,
        \emph{x - -} não retorna dois tokens, mas três. Identificadores não podem começar com números e nem underscores.
\end{itemize}

\section{Dificuldades encontradas}

Não foram encontradas muitas dificuldades no desenvolvimento do trabalho. A única que vale a pena
ser mencionada é a identificação de erros que o analisador não percebe imediatamente.
Um exemplo é identificar números seguidos de letras como um erro léxico. O analisador léxico retorna dois tokens,
\textless T\_NUM\textgreater e \textless T\_ID\textgreater, ao invés de cair na regra de token não identificado. Para tratar este tipo de erro, uma regra foi
adicionada para cada um.

\section{Referências Bibliográficas}
[1] The Haskell 98 Report - https://www.haskell.org/onlinereport/index.html $^1$

$^1$ Utilizado como referência para estruturas da linguagem Haskell e predecências de operadores.

\section{Anexo: Gramática}

\begin{lstlisting}[basicstyle=\small]
program:  
    line_elems

line_elems: 
    line_elem line_elems
    | line_elem

line_elem:
    fundecl
    | procdecl
    | funtype_decl

fundecl: 
    ID args '=' expr ';'
    | ID args '=' expr where_exp 
    | ID '=' expr ';'
    | ID '=' expr where_exp

args:
    arg_value args 
    | arg_value
    | WILDSCORE

arg_value:
    list_value
    | basic_value
    | '(' arg_value ')'

basic_value: 
    INT
    | FLOAT
    | TRUE
    | FALSE
    | ID
    | '(' ')'

list_value:
    arg_value ':' list_value
    | built_list_value

built_list_value:
    '[' ']'
    | '[' args ']'

funtype_decl:
    ID '::' funtype ';'

funtype:
    basic_type
    | '(' funtype ')'
    | basic_type '->' funtype

basic_type:
    INTEGER
    | FLOAT_T
    | BOOL
    | '[' types ']' 
    | ID
    | '(' ')'

types:
    basic_type
    | basic_type ',' types

expr:
    op_prec1
    | appexp
    | ifexpr
    | yieldexpr

ifexpr:
    'if' expr 'then' '{' expr '}' 'else' '{' expr '}'

yieldexpr:
    "yield" ifexpr
    | "yield" appexpr
    | "yield" op_prec1


op_prec1:
     op_prec2 '||' op_prec1
     | op_prec2

op_prec2:
     op_prec3 '&&' op_prec2
     | op_prec3

op_prec3:
     op_prec3 '==' op_prec4
     | op_prec3 '/=' op_prec4
     | op_prec3 '<' op_prec4
     | op_prec3 '<=' op_prec4
     | op_prec3 '>' op_prec4
     | op_prec3 '>=' op_prec4
     op_prec4

op_prec4:
     op_prec5 ':' op_prec4
     | op_prec5 '++' op_prec4
     | op_prec5

op_prec5:
    op_prec5 '+' op_prec6
    | op_prec5 '-' op_prec6
    | op_prec6

op_prec6:
     op_prec6 '%' op_prec7
     | op_prec7

op_prec7:
    op_prec7 '*' op_prec8
    | op_prec7 '/' op_prec8
    | op_prec8

op_prec8:
    basic_value
    | list_expr
    | '(' expr ')'
    | '-' expr

exprs:
    expr
    | expr ',' exprs


list_expr:
    | '[' exprs ']'
    | '[' ']'

appexp:
    ID expr

where_exp:
    'where' '{' line_elems '}' 

procdecl:
    ID args '=' 'do' '{' stmts '}'
    | ID args '=' 'do' '{' stmts '}' where_exp
    | ID '=' 'do' '{' stmts '}'
    | ID '=' 'do' '{' stmts '}' where_exp

stmts:
    stmt
    | stmt stmts

stmt:
    basic_value '<-' expr ';'
    | basic_value '<-' while_expr ';'
    | basic_value '<-' io_stmt ';'
    | expr ';'
    | while_expr ';'
    | io_stmt ';'

io_stmt:
    | 'readInt'
    | 'readFloat'
    | 'readBool'
    | 'print' expr

while_expr:
    'while' '(' expr ')' '{' stmts '}' 
\end{lstlisting}


\end{document}
